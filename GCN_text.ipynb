{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "GCN_text.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "146940a0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re, json, itertools\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "id": "146940a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31ae60cd"
      },
      "source": [
        "df = pd.read_excel('posts.xlsx')"
      ],
      "id": "31ae60cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39d6a703",
        "outputId": "e0da7a5e-63f0-4ee8-f602-4af68d28eb75"
      },
      "source": [
        "df.shape"
      ],
      "id": "39d6a703",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39362, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b63ba32"
      },
      "source": [
        "df = df[['Attribute:Body', 'Attribute:Tags']]\n",
        "df.columns = ['Body', 'Tags']\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "df = df.iloc[:10000, :]"
      ],
      "id": "7b63ba32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1f2871d2",
        "outputId": "2c734d45-a601-4152-cdf1-838df3222367"
      },
      "source": [
        "df.head()"
      ],
      "id": "1f2871d2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;p&gt;I often hear about subatomic particles havi...</td>\n",
              "      <td>&lt;quantum-mechanics&gt;&lt;particle-physics&gt;&lt;angular-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;p&gt;How would you explain string theory to non-...</td>\n",
              "      <td>&lt;string-theory&gt;&lt;education&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;p&gt;This is a question that has been posted at ...</td>\n",
              "      <td>&lt;particle-physics&gt;&lt;group-theory&gt;&lt;representatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;p&gt;What are the main problems that we need to ...</td>\n",
              "      <td>&lt;quantum-mechanics&gt;&lt;quantum-interpretations&gt;&lt;h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;p&gt;Hamilton's principle states that a dynamic ...</td>\n",
              "      <td>&lt;lagrangian-formalism&gt;&lt;variational-principle&gt;&lt;...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Body                                               Tags\n",
              "0  <p>I often hear about subatomic particles havi...  <quantum-mechanics><particle-physics><angular-...\n",
              "1  <p>How would you explain string theory to non-...                         <string-theory><education>\n",
              "2  <p>This is a question that has been posted at ...  <particle-physics><group-theory><representatio...\n",
              "3  <p>What are the main problems that we need to ...  <quantum-mechanics><quantum-interpretations><h...\n",
              "4  <p>Hamilton's principle states that a dynamic ...  <lagrangian-formalism><variational-principle><..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6bcd2f9"
      },
      "source": [
        "#preprocessing the Body\n",
        "def clean_text(sentence):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    sentence = re.sub(cleanr, '', sentence)\n",
        "    pattern = re.compile(r'[^a-z]+')\n",
        "    sentence = sentence.lower()\n",
        "    sentence = pattern.sub(' ', sentence).strip()\n",
        "    word_list = word_tokenize(sentence)\n",
        "#     stopwords_list = set(stopwords.words('english'))\n",
        "#     word_list = [word for word in word_list if word not in stopwords_list]\n",
        "#     word_list = [word for word in word_list if len(word)>1]\n",
        "#     ps = PorterStemmer()\n",
        "#     word_list = [ps.stem(word) for word in word_list]\n",
        "    sentence = ' '.join(word_list)\n",
        "    return sentence\n",
        "df['Body'] = df['Body'].apply(lambda x: clean_text(x))"
      ],
      "id": "e6bcd2f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9f50ea81",
        "outputId": "ad6ab845-3a26-4eac-ed0e-9d8359b2aac4"
      },
      "source": [
        "df.head()"
      ],
      "id": "9f50ea81",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i often hear about subatomic particles having ...</td>\n",
              "      <td>&lt;quantum-mechanics&gt;&lt;particle-physics&gt;&lt;angular-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how would you explain string theory to non phy...</td>\n",
              "      <td>&lt;string-theory&gt;&lt;education&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this is a question that has been posted at man...</td>\n",
              "      <td>&lt;particle-physics&gt;&lt;group-theory&gt;&lt;representatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what are the main problems that we need to sol...</td>\n",
              "      <td>&lt;quantum-mechanics&gt;&lt;quantum-interpretations&gt;&lt;h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hamilton s principle states that a dynamic sys...</td>\n",
              "      <td>&lt;lagrangian-formalism&gt;&lt;variational-principle&gt;&lt;...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Body                                               Tags\n",
              "0  i often hear about subatomic particles having ...  <quantum-mechanics><particle-physics><angular-...\n",
              "1  how would you explain string theory to non phy...                         <string-theory><education>\n",
              "2  this is a question that has been posted at man...  <particle-physics><group-theory><representatio...\n",
              "3  what are the main problems that we need to sol...  <quantum-mechanics><quantum-interpretations><h...\n",
              "4  hamilton s principle states that a dynamic sys...  <lagrangian-formalism><variational-principle><..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "bc34e21d",
        "outputId": "048694ce-2c33-468f-b78b-d295d96d5826"
      },
      "source": [
        "#creating one-hot representation for all the tags\n",
        "df_tags = pd.DataFrame(np.zeros((df.shape[0], len_tags), dtype=int), columns=tags)\n",
        "for i in range(len_rows):\n",
        "    for x in df.Tags[i].split():\n",
        "        df_tags[x][i] = 1\n",
        "df = pd.concat([df, df_tags], axis=1)\n",
        "df.head()"
      ],
      "id": "bc34e21d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "      <th>1pi-effective-action</th>\n",
              "      <th>absolute-units</th>\n",
              "      <th>absorption</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>accelerator-physics</th>\n",
              "      <th>accretion-disk</th>\n",
              "      <th>acoustics</th>\n",
              "      <th>action</th>\n",
              "      <th>adiabatic</th>\n",
              "      <th>adm-formalism</th>\n",
              "      <th>ads-cft</th>\n",
              "      <th>aerodynamics</th>\n",
              "      <th>aether</th>\n",
              "      <th>affine-lie-algebra</th>\n",
              "      <th>air</th>\n",
              "      <th>aircraft</th>\n",
              "      <th>algebraic-geometry</th>\n",
              "      <th>algebraic-topology</th>\n",
              "      <th>algorithms</th>\n",
              "      <th>amorphous-solids</th>\n",
              "      <th>analyticity</th>\n",
              "      <th>angular-momentum</th>\n",
              "      <th>angular-velocity</th>\n",
              "      <th>antennas</th>\n",
              "      <th>anthropic-principle</th>\n",
              "      <th>anti-de-sitter-spacetime</th>\n",
              "      <th>anticommutator</th>\n",
              "      <th>antimatter</th>\n",
              "      <th>anyons</th>\n",
              "      <th>applied-physics</th>\n",
              "      <th>approximations</th>\n",
              "      <th>arrow-of-time</th>\n",
              "      <th>asteroids</th>\n",
              "      <th>astrometrics</th>\n",
              "      <th>astronomy</th>\n",
              "      <th>astrophotography</th>\n",
              "      <th>astrophysics</th>\n",
              "      <th>asymptotics</th>\n",
              "      <th>...</th>\n",
              "      <th>variational-calculus</th>\n",
              "      <th>variational-principle</th>\n",
              "      <th>vector-fields</th>\n",
              "      <th>vectors</th>\n",
              "      <th>velocity</th>\n",
              "      <th>vibrations</th>\n",
              "      <th>virial-theorem</th>\n",
              "      <th>virtual-particles</th>\n",
              "      <th>viscosity</th>\n",
              "      <th>visible-light</th>\n",
              "      <th>vision</th>\n",
              "      <th>visualization</th>\n",
              "      <th>voltage</th>\n",
              "      <th>volume</th>\n",
              "      <th>vortex</th>\n",
              "      <th>warp-drives</th>\n",
              "      <th>water</th>\n",
              "      <th>wave-particle-duality</th>\n",
              "      <th>wavefunction</th>\n",
              "      <th>wavefunction-collapse</th>\n",
              "      <th>waveguide</th>\n",
              "      <th>wavelength</th>\n",
              "      <th>waves</th>\n",
              "      <th>weak-interaction</th>\n",
              "      <th>weather</th>\n",
              "      <th>weight</th>\n",
              "      <th>white-dwarfs</th>\n",
              "      <th>white-holes</th>\n",
              "      <th>wick-rotation</th>\n",
              "      <th>wick-theorem</th>\n",
              "      <th>wightman-fields</th>\n",
              "      <th>wigner-eckart</th>\n",
              "      <th>wigner-transform</th>\n",
              "      <th>wilson-loop</th>\n",
              "      <th>wimps</th>\n",
              "      <th>work</th>\n",
              "      <th>wormholes</th>\n",
              "      <th>x-ray-crystallography</th>\n",
              "      <th>x-rays</th>\n",
              "      <th>yang-mills</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i often hear about subatomic particles having ...</td>\n",
              "      <td>quantum-mechanics  particle-physics  angular-...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how would you explain string theory to non phy...</td>\n",
              "      <td>string-theory  education</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this is a question that has been posted at man...</td>\n",
              "      <td>particle-physics  group-theory  representatio...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what are the main problems that we need to sol...</td>\n",
              "      <td>quantum-mechanics  quantum-interpretations  h...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hamilton s principle states that a dynamic sys...</td>\n",
              "      <td>lagrangian-formalism  variational-principle  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 725 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Body  ... yang-mills\n",
              "0  i often hear about subatomic particles having ...  ...          0\n",
              "1  how would you explain string theory to non phy...  ...          0\n",
              "2  this is a question that has been posted at man...  ...          0\n",
              "3  what are the main problems that we need to sol...  ...          0\n",
              "4  hamilton s principle states that a dynamic sys...  ...          0\n",
              "\n",
              "[5 rows x 725 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9a52951",
        "outputId": "47d2226b-888e-4d65-9338-af397c4829dd"
      },
      "source": [
        "#list of all tags\n",
        "def clean_tag(line):\n",
        "    line = re.sub('[<>]', ' ', line)\n",
        "    return line\n",
        "df.Tags = df.Tags.apply(lambda x: clean_tag(x))\n",
        "vectorizer = CountVectorizer(tokenizer= lambda text : text.split(\" \"))\n",
        "tag_dtm = vectorizer.fit_transform(df[\"Tags\"])\n",
        "tags = vectorizer.get_feature_names()\n",
        "tags = [x for x in tags if x]\n",
        "len_rows = df.shape[0]\n",
        "len_tags = len(tags)\n",
        "print('Total no. of unique tags: ',len_tags)\n",
        "print('dataframe size: ', len_rows)\n",
        "tags_count = {}\n",
        "temp_series = df_tags.sum().sort_values(ascending=False)\n",
        "for i in range(len_tags):\n",
        "    tags_count[temp_series.index[i]] = temp_series.values[i]"
      ],
      "id": "b9a52951",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of unique tags:  723\n",
            "dataframe size:  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "130712a9",
        "outputId": "1c152cc3-89bb-4acd-8fdf-16bd20fe5f6f"
      },
      "source": [
        "!wget 'https://nlp.stanford.edu/data/glove.6B.zip'\n",
        "!unzip 'glove.6B.zip'"
      ],
      "id": "130712a9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-17 15:28:08--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-07-17 15:28:08--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  5.03MB/s    in 2m 40s  \n",
            "\n",
            "2021-07-17 15:30:48 (5.14 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.50d.txt        \n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.100d.txt       \n",
            "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d57da0ad"
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open('glove.6B.50d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "id": "d57da0ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a40fe616",
        "outputId": "95e3c88c-9611-4deb-dc6e-6e7d922eb917"
      },
      "source": [
        "tags[:10]"
      ],
      "id": "a40fe616",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1pi-effective-action',\n",
              " 'absolute-units',\n",
              " 'absorption',\n",
              " 'acceleration',\n",
              " 'accelerator-physics',\n",
              " 'accretion-disk',\n",
              " 'acoustics',\n",
              " 'action',\n",
              " 'adiabatic',\n",
              " 'adm-formalism']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c66c531b"
      },
      "source": [
        "#getting tag embeddings\n",
        "tag_embeddings = []\n",
        "count = 0\n",
        "for tag in tags:\n",
        "    sum = np.zeros(50)\n",
        "    try:\n",
        "        sub_tags = tag.split('-')\n",
        "        for x in sub_tags:\n",
        "            try:\n",
        "                sum += embeddings_index[x]\n",
        "            except:\n",
        "                continue\n",
        "        tag_embeddings.append(sum/len(sub_tags))\n",
        "    except:\n",
        "        count+=1\n",
        "        print(tag)\n",
        "tag_embeddings = np.array(tag_embeddings)"
      ],
      "id": "c66c531b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "a2264ebd",
        "outputId": "8ed774bf-1a74-4cba-c27d-e96ff4444a8c"
      },
      "source": [
        "df.head()"
      ],
      "id": "a2264ebd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "      <th>1pi-effective-action</th>\n",
              "      <th>absolute-units</th>\n",
              "      <th>absorption</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>accelerator-physics</th>\n",
              "      <th>accretion-disk</th>\n",
              "      <th>acoustics</th>\n",
              "      <th>action</th>\n",
              "      <th>adiabatic</th>\n",
              "      <th>adm-formalism</th>\n",
              "      <th>ads-cft</th>\n",
              "      <th>aerodynamics</th>\n",
              "      <th>aether</th>\n",
              "      <th>affine-lie-algebra</th>\n",
              "      <th>air</th>\n",
              "      <th>aircraft</th>\n",
              "      <th>algebraic-geometry</th>\n",
              "      <th>algebraic-topology</th>\n",
              "      <th>algorithms</th>\n",
              "      <th>amorphous-solids</th>\n",
              "      <th>analyticity</th>\n",
              "      <th>angular-momentum</th>\n",
              "      <th>angular-velocity</th>\n",
              "      <th>antennas</th>\n",
              "      <th>anthropic-principle</th>\n",
              "      <th>anti-de-sitter-spacetime</th>\n",
              "      <th>anticommutator</th>\n",
              "      <th>antimatter</th>\n",
              "      <th>anyons</th>\n",
              "      <th>applied-physics</th>\n",
              "      <th>approximations</th>\n",
              "      <th>arrow-of-time</th>\n",
              "      <th>asteroids</th>\n",
              "      <th>astrometrics</th>\n",
              "      <th>astronomy</th>\n",
              "      <th>astrophotography</th>\n",
              "      <th>astrophysics</th>\n",
              "      <th>asymptotics</th>\n",
              "      <th>...</th>\n",
              "      <th>variational-calculus</th>\n",
              "      <th>variational-principle</th>\n",
              "      <th>vector-fields</th>\n",
              "      <th>vectors</th>\n",
              "      <th>velocity</th>\n",
              "      <th>vibrations</th>\n",
              "      <th>virial-theorem</th>\n",
              "      <th>virtual-particles</th>\n",
              "      <th>viscosity</th>\n",
              "      <th>visible-light</th>\n",
              "      <th>vision</th>\n",
              "      <th>visualization</th>\n",
              "      <th>voltage</th>\n",
              "      <th>volume</th>\n",
              "      <th>vortex</th>\n",
              "      <th>warp-drives</th>\n",
              "      <th>water</th>\n",
              "      <th>wave-particle-duality</th>\n",
              "      <th>wavefunction</th>\n",
              "      <th>wavefunction-collapse</th>\n",
              "      <th>waveguide</th>\n",
              "      <th>wavelength</th>\n",
              "      <th>waves</th>\n",
              "      <th>weak-interaction</th>\n",
              "      <th>weather</th>\n",
              "      <th>weight</th>\n",
              "      <th>white-dwarfs</th>\n",
              "      <th>white-holes</th>\n",
              "      <th>wick-rotation</th>\n",
              "      <th>wick-theorem</th>\n",
              "      <th>wightman-fields</th>\n",
              "      <th>wigner-eckart</th>\n",
              "      <th>wigner-transform</th>\n",
              "      <th>wilson-loop</th>\n",
              "      <th>wimps</th>\n",
              "      <th>work</th>\n",
              "      <th>wormholes</th>\n",
              "      <th>x-ray-crystallography</th>\n",
              "      <th>x-rays</th>\n",
              "      <th>yang-mills</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i often hear about subatomic particles having ...</td>\n",
              "      <td>quantum-mechanics  particle-physics  angular-...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how would you explain string theory to non phy...</td>\n",
              "      <td>string-theory  education</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this is a question that has been posted at man...</td>\n",
              "      <td>particle-physics  group-theory  representatio...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what are the main problems that we need to sol...</td>\n",
              "      <td>quantum-mechanics  quantum-interpretations  h...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hamilton s principle states that a dynamic sys...</td>\n",
              "      <td>lagrangian-formalism  variational-principle  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 725 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Body  ... yang-mills\n",
              "0  i often hear about subatomic particles having ...  ...          0\n",
              "1  how would you explain string theory to non phy...  ...          0\n",
              "2  this is a question that has been posted at man...  ...          0\n",
              "3  what are the main problems that we need to sol...  ...          0\n",
              "4  hamilton s principle states that a dynamic sys...  ...          0\n",
              "\n",
              "[5 rows x 725 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "143bfb25"
      },
      "source": [
        "# !pip install stellargraph"
      ],
      "id": "143bfb25",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df84cdf4"
      },
      "source": [
        "#importing libraries\n",
        "import tensorflow as tf\n",
        "from pickle import load\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.activations import sigmoid\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, Embedding, GlobalMaxPooling1D, dot, Reshape, Layer\n",
        "from tensorflow.keras.backend import variable, dot as k_dot, sigmoid, relu\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from tensorflow import Variable\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "df84cdf4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77c5667a"
      },
      "source": [
        "### Embedding of questions"
      ],
      "id": "77c5667a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04abfe33"
      },
      "source": [
        "def create_tokenizer(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer\n",
        "\n",
        "def max_length(lines):\n",
        "    return max([len(s.split()) for s in lines])\n",
        "\n",
        "def encode_text(tokenizer, lines, length):\n",
        "    encoded = tokenizer.texts_to_sequences(lines)\n",
        "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
        "    return padded"
      ],
      "id": "04abfe33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b2ed914"
      },
      "source": [
        "X = df['Body']\n",
        "y = df.drop(['Body', 'Tags'], axis=1)"
      ],
      "id": "0b2ed914",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ffa10fb",
        "outputId": "be465b23-d829-45fe-d775-b0f1c99b38fb"
      },
      "source": [
        "tokenizer = create_tokenizer(X)\n",
        "length = max_length(X)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Max document length: %d' % length)\n",
        "print('Vocabulary size: %d' % vocab_size)"
      ],
      "id": "9ffa10fb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max document length: 3325\n",
            "Vocabulary size: 24280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e8dd94c",
        "outputId": "40c3e6da-e82b-4739-b5cf-e4428b5c2b5c"
      },
      "source": [
        "X = encode_text(tokenizer, X, length)\n",
        "print(X.shape)"
      ],
      "id": "0e8dd94c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 3325)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ac2a43b"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "id": "2ac2a43b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbb8b6ff"
      },
      "source": [
        "### Adjacency Matrix"
      ],
      "id": "dbb8b6ff"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70757a51"
      },
      "source": [
        "adj_matrix_path = 'adjacency_matrix.json'\n",
        "# Count all labels.\n",
        "nums = np.sum(np.array(df_tags), axis=0)\n",
        "adj = np.zeros((len_tags, len_tags), dtype=int)\n",
        "# Now iterate over the whole training set and consider all pairs of labels in sample annotation.\n",
        "for sample in np.array(df_tags):\n",
        "    sample_idx = np.argwhere(sample > 0)[:, 0]\n",
        "    # We count all possible pairs that can be created from each sample's set of labels.\n",
        "    for i, j in itertools.combinations(sample_idx, 2):\n",
        "        adj[i, j] += 1\n",
        "        adj[j, i] += 1\n",
        "# Save it for further use.        \n",
        "with open(adj_matrix_path, 'w') as fp:\n",
        "    json.dump({\n",
        "        'nums': nums.tolist(),\n",
        "        'adj': adj.tolist()\n",
        "    }, fp, indent=3)"
      ],
      "id": "70757a51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a44f315"
      },
      "source": [
        ""
      ],
      "id": "6a44f315",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66c25224",
        "outputId": "e29d811f-21b7-4fba-f626-bc9632db3bba"
      },
      "source": [
        "# GCNConv.preprocess(adj).astype('f4')\n",
        "tag_embeddings.shape"
      ],
      "id": "66c25224",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(723, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b42a36a"
      },
      "source": [
        "### Defining Model"
      ],
      "id": "7b42a36a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "437977f7",
        "outputId": "7baf80b0-3ab2-4ceb-94a1-4567390d76bc"
      },
      "source": [
        "def custom_model(length, vocab_size, tag_embeddings, adj):\n",
        "    inputs1 = Input(shape=(length, ))\n",
        "    embedding = Embedding(vocab_size, 50)(inputs1)\n",
        "    conv = Conv1D(filters=50, kernel_size=4, activation='relu')(embedding)\n",
        "    pool = GlobalMaxPooling1D()(conv)\n",
        "    model = Model(inputs1, pool)\n",
        "    print(model.summary())\n",
        "    \n",
        "#     X_in = Input(shape=(len(tag_embeddings[0]), ))\n",
        "# #     fltr_in = Input((len(tag_embeddings), ))\n",
        "      \n",
        "#     graph_conv_1 = GCNConv(50, activation='relu')([X_in, adj])\n",
        "#     graph_conv_2 = GCNConv(50, activation='relu')([graph_conv_1, adj])\n",
        "#     print(pool.shape)\n",
        "#     print(graph_conv_2.shape)\n",
        "#     output = tf.matmul(pool, tf.transpose(graph_conv_2))\n",
        "#     output = sigmoid(output)\n",
        "#     print(output.shape)\n",
        "    \n",
        "#     gcn = Model(inputs = [inputs1, X_in], outputs = output)\n",
        "#     print(gcn.summary())\n",
        "#     gcn.compile(optimizer='adam', loss='binary_crossentropy', weighted_metrics=['acc'])\n",
        "#     gcn.fit([X, tag_embeddings] , y.values, epochs=10)\n",
        "custom_model(length, vocab_size, tag_embeddings, adj)"
      ],
      "id": "437977f7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 3325)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 3325, 50)          1214000   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 3322, 50)          10050     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 50)                0         \n",
            "=================================================================\n",
            "Total params: 1,224,050\n",
            "Trainable params: 1,224,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55222694",
        "outputId": "4a2c5a9a-e88a-461c-ef6b-1a0eda5c54ba"
      },
      "source": [
        "print(length)\n",
        "print(vocab_size)"
      ],
      "id": "55222694",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3325\n",
            "24280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16602cc5"
      },
      "source": [
        "### Pytorch Implementation"
      ],
      "id": "16602cc5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85af34ae"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ],
      "id": "85af34ae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYW_xjEZ9i8S"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "device\n",
        "X_train = torch.from_numpy(X_train)\n",
        "y_train = torch.from_numpy(np.array(y_train))\n",
        "X_val = torch.from_numpy(X_val)\n",
        "y_val = torch.from_numpy(np.array(y_val))\n",
        "tag_embeddings = torch.from_numpy(tag_embeddings)"
      ],
      "id": "NYW_xjEZ9i8S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0d43ce7"
      },
      "source": [
        "# function for creating adjacency matrix (over-smoothing problem is also taken into consideration)\n",
        "'''\n",
        "num_classes ---> no. of unique tags\n",
        "t ---> threshold for binarizing the correlation matrix.\n",
        "p ---> determines the weights assigned to a node itself and other correlated nodes\n",
        "adj_data ---> contains co-occurrence matrix and corresponding tag counts\n",
        "    \n",
        "*Note -> for info. regarding all these parameters go to https://arxiv.org/pdf/1904.03582.pdf\n",
        "'''\n",
        "\n",
        "t = 0.4\n",
        "p = 0.2\n",
        "def gen_A(len_tags, t, p, adj_data):\n",
        "    adj = np.array(adj_data['adj']).astype(np.float32)\n",
        "    nums = np.array(adj_data['nums']).astype(np.float32)\n",
        "    nums = nums[:, np.newaxis]\n",
        "    adj = adj / nums\n",
        "    adj[adj < t] = 0\n",
        "    adj[adj >= t] = 1\n",
        "    adj = adj * p / (adj.sum(0, keepdims=True) + 1e-6)  \n",
        "    adj = adj + np.identity(len_tags, np.int)\n",
        "    return adj\n",
        "\n",
        "#normalization of Adjacency matrix\n",
        "def gen_adj(A):\n",
        "    D = torch.pow(A.sum(1).float(), -0.5)\n",
        "    D = torch.diag(D).type_as(A)\n",
        "    adj = torch.matmul(torch.matmul(A, D).t(), D)\n",
        "    return adj"
      ],
      "id": "d0d43ce7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91b54aa8",
        "outputId": "c9bcb42b-2533-4ba0-abb3-37786e7e6213"
      },
      "source": [
        "#defining Graph Convolution Network\n",
        "\"\"\"\n",
        "Simple GCN layer (pytorch), similar to https://arxiv.org/abs/1609.02907\n",
        "\n",
        "\"\"\"\n",
        "class GraphConvolution(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_features, out_features, bias=False):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = nn.Parameter(torch.Tensor(in_features, out_features), requires_grad=True)\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(1, 1, out_features), requires_grad=True)\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        support = torch.matmul(input.float(), self.weight)\n",
        "        output = torch.matmul(adj, support)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'\n",
        "\n",
        "\n",
        "class TagRetrieval(nn.Module):\n",
        "    \n",
        "    def __init__(self, len_tags, adj_matrix_path, vocab_size, embedding_dim, t=0.1, p=0.25):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.conv1d = nn.Conv1d(embedding_dim, embedding_dim, 4, padding=0)\n",
        "        self.globalmaxpool1d = nn.AdaptiveMaxPool2d(output_size=(embedding_dim, 1))\n",
        "        \n",
        "        self.gc1 = GraphConvolution(50, 50)\n",
        "        self.gc2 = GraphConvolution(50, 50)\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "        # Load data for adjacency matrix\n",
        "        with open(adj_matrix_path) as fp:\n",
        "            adj_data = json.load(fp)\n",
        "        # Compute adjacency matrix\n",
        "        adj = gen_A(len_tags, t, p, adj_data)\n",
        "        self.A = nn.Parameter(torch.from_numpy(adj).float(), requires_grad=False)\n",
        "        \n",
        "    def forward(self, question, tags_embeddings):\n",
        "        # Get visual features from image\n",
        "        #feature = self.features(imgs)\n",
        "        #feature = feature.view(feature.size(0), -1)\n",
        "        embedding = self.embedding(question)\n",
        "        embedding = embedding.permute([0, 2, 1])\n",
        "        conv1d = self.conv1d(embedding)\n",
        "        globalmaxpool1d = self.globalmaxpool1d(conv1d)\n",
        "        feature = globalmaxpool1d.squeeze()\n",
        "        # Get graph features from graph\n",
        "        #inp = inp[0].squeeze()\n",
        "        inp = tag_embeddings\n",
        "        adj = gen_adj(self.A).detach()\n",
        "        x = self.gc1(inp, adj)\n",
        "        x = self.relu(x)\n",
        "        x = self.gc2(x, adj)\n",
        "        \n",
        "        # We multiply the features from GСN and СNN in order to take into account \n",
        "        # the contribution to the prediction of classes from both the image and the graph.\n",
        "        x = x.transpose(0, 1)\n",
        "        x = torch.matmul(feature, x)\n",
        "        return self.sigm(x)\n",
        "    \n",
        "model = TagRetrieval(len_tags, adj_matrix_path, vocab_size, 50)\n",
        "# model = model.to(device)\n",
        "# print(model(X_train[:1000, :], tag_embeddings).shape)\n",
        "    \n",
        "print(model.parameters)\n"
      ],
      "id": "91b54aa8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.parameters of TagRetrieval(\n",
            "  (embedding): Embedding(24280, 50, padding_idx=0)\n",
            "  (conv1d): Conv1d(50, 50, kernel_size=(4,), stride=(1,))\n",
            "  (globalmaxpool1d): AdaptiveMaxPool2d(output_size=(50, 1))\n",
            "  (gc1): GraphConvolution (50 -> 50)\n",
            "  (gc2): GraphConvolution (50 -> 50)\n",
            "  (relu): LeakyReLU(negative_slope=0.2)\n",
            "  (sigm): Sigmoid()\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmd-U4jk8nzu"
      },
      "source": [
        "# X_train = X_train.to(device)\n",
        "# y_train = y_train.to(device)\n",
        "# X_val = X_val.to(device)\n",
        "# y_val = y_val.to(device)\n",
        "# tag_embeddings = tag_embeddings.to(device)"
      ],
      "id": "hmd-U4jk8nzu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ujw7NsSAjCO",
        "outputId": "1c2e7a31-2594-49c2-9452-5af82800c728"
      },
      "source": [
        "X_train.device"
      ],
      "id": "1ujw7NsSAjCO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnSOTErzA-CI"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCELoss()"
      ],
      "id": "ZnSOTErzA-CI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uE9hSr3A-FL"
      },
      "source": [
        "for epoch in range(5):\n",
        "  optimizer.zero_grad()\n",
        "  model_result = model(X_train, tag_embeddings)\n",
        "  loss = criterion(model_result, y_train.float())\n",
        "  print('Epoch no: {} and the loss : {}'.format(epoch+1, loss))\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "id": "2uE9hSr3A-FL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0jxYdF6A-Nj"
      },
      "source": [
        ""
      ],
      "id": "V0jxYdF6A-Nj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTOOsx4NA-S0"
      },
      "source": [
        ""
      ],
      "id": "yTOOsx4NA-S0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KC2huMrA-YR"
      },
      "source": [
        ""
      ],
      "id": "0KC2huMrA-YR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4730e4f8",
        "outputId": "d0520acf-bd9b-47b3-d32c-3dc12ea193d9"
      },
      "source": [
        "x = torch.tensor([[1,2, 12,34, 56,78, 90,80],\n",
        "                 [12,45, 99,67, 6,23, 77,82],\n",
        "                 [3,24, 6,99, 12,56, 21,22]])\n",
        "embed = nn.Embedding(3325, 50, padding_idx=0)\n",
        "print(x.shape)\n",
        "x = embed(x)\n",
        "print(x.shape)\n",
        "x = x.permute([0, 2, 1])\n",
        "print(x.shape)\n",
        "conv1d = nn.Conv1d(50, 50, 4, padding=0)\n",
        "x = conv1d(x)\n",
        "print(x.shape)\n",
        "globalmaxpool1d = nn.AdaptiveMaxPool2d(output_size=(50, 1))\n",
        "x = globalmaxpool1d(x)\n",
        "print(x.shape)\n",
        "x = x.squeeze()\n",
        "print(x.shape)\n",
        "\n",
        "\n",
        "gc1 = GraphConvolution(50, 50)\n",
        "y = gc1(torch.from_numpy(tag_embeddings), A)\n",
        "print(y.shape)\n",
        "gc2 = GraphConvolution(50, 50)\n",
        "y = gc2(y, A)\n",
        "print(y.shape)\n",
        "y = y.transpose(0, 1)\n",
        "print(y.shape)\n",
        "y = torch.matmul(x, y)\n",
        "print(y.shape)\n",
        "sigm = nn.Sigmoid()\n",
        "y = sigm(y)\n",
        "print(y.shape)"
      ],
      "id": "4730e4f8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 8])\n",
            "torch.Size([3, 8, 50])\n",
            "torch.Size([3, 50, 8])\n",
            "torch.Size([3, 50, 5])\n",
            "torch.Size([3, 50, 1])\n",
            "torch.Size([3, 50])\n",
            "torch.Size([723, 50])\n",
            "torch.Size([723, 50])\n",
            "torch.Size([50, 723])\n",
            "torch.Size([3, 723])\n",
            "torch.Size([3, 723])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06a540f2",
        "outputId": "9ae5fecc-818f-417c-e245-9a04ec0111ff"
      },
      "source": [
        "with open(adj_matrix_path) as fp:\n",
        "    adj_data = json.load(fp)\n",
        "# Compute adjacency matrix\n",
        "adj = gen_A(len_tags, t, p, adj_data)\n",
        "A = nn.Parameter(torch.from_numpy(adj).float(), requires_grad=False)\n",
        "A.shape"
      ],
      "id": "06a540f2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([723, 723])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "842b4f5d",
        "outputId": "62533bd0-a28c-46a2-d432-a6f5b347628a"
      },
      "source": [
        "A"
      ],
      "id": "842b4f5d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c7c357d",
        "outputId": "6ac742c9-247f-4f5e-ab8c-7baef2ed844e"
      },
      "source": [
        "type(torch.from_numpy(tag_embeddings))"
      ],
      "id": "8c7c357d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce4aada1",
        "outputId": "782902d3-75f1-4c45-e096-3a3436104189"
      },
      "source": [
        "X_train[:100, :].shape"
      ],
      "id": "ce4aada1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 3325)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6b767cd",
        "outputId": "828375fc-58e1-41a9-e77f-4059484a74e9"
      },
      "source": [
        "X_train.shape"
      ],
      "id": "c6b767cd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8000, 3325])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMRKNN6WCdur",
        "outputId": "0fb2d3d5-46f8-46cd-cb65-87711b850a11"
      },
      "source": [
        "X_train[:5000].shape"
      ],
      "id": "IMRKNN6WCdur",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5000, 3325])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9aKKL0BCjsn"
      },
      "source": [
        ""
      ],
      "id": "x9aKKL0BCjsn",
      "execution_count": null,
      "outputs": []
    }
  ]
}